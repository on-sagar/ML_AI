{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#one neuron with four inputs and one output\n",
    "\n",
    "inputs=[1,2,3,2.5]\n",
    "weights=[0.2,0.8,-0.5,1.0]\n",
    "bias=2\n",
    "\n",
    "\n",
    "output=inputs[0]*weights[0]+inputs[1]*weights[1]+inputs[2]*weights[2]+inputs[3]*weights[3]+bias\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 3.985]\n"
     ]
    }
   ],
   "source": [
    "#three neurons with four inputs and each have single output\n",
    "\n",
    "weights1=[0.2,0.8,-0.5,1.0]\n",
    "weights2=[0.5,-0.91,0.26,-0.5]\n",
    "weights3=[0.26,0.27,0.17,0.87]\n",
    "\n",
    "bias1=2\n",
    "bias2=3\n",
    "bias3=0.5\n",
    "\n",
    "#outputs from three neurons\n",
    "output= [inputs[0]*weights1[0]+inputs[1]*weights1[1]+inputs[2]*weights1[2]+inputs[3]*weights1[3]+bias1,\n",
    "         inputs[0]*weights2[0]+inputs[1]*weights2[1]+inputs[2]*weights2[2]+inputs[3]*weights2[3]+bias2,\n",
    "         inputs[0]*weights3[0]+inputs[1]*weights3[1]+inputs[2]*weights3[2]+inputs[3]*weights3[3]+bias3]\n",
    "print(output)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   0.21  3.885]\n"
     ]
    }
   ],
   "source": [
    "##a more compact technique\n",
    "inputs=[1,2,3,2.5]\n",
    "\n",
    "weights=[[0.2,0.8,-0.5,1.0],\n",
    "         [0.5,-0.91,0.26,-0.5],\n",
    "         [-0.26,-0.27,0.17,0.87]]\n",
    "biases=[2,3,0.5]\n",
    "\n",
    "# layer_outputs=[]\n",
    "# for neuron_weights,neuron_bias in zip(weights,biases): #zip combines two lists element-wise\n",
    "#     neuron_output=0\n",
    "#     for n_input,weight in zip(inputs,neuron_weights):\n",
    "#         neuron_output+=n_input*weight\n",
    "#     neuron_output+=neuron_bias\n",
    "#     layer_outputs.append(neuron_output)\n",
    "# # print(layer_outputs)\n",
    "\n",
    "\n",
    "'''DOT PRODUCT'''\n",
    "'''USED TO MULTIPLY ELMENT WISE INPUTS AND BIASES IN NN CALCULATIONS'''\n",
    "# inputs=[1,2,3,2.5]\n",
    "# weights=[0.2,0.8,-0.5,1.0]\n",
    "# bias=2\n",
    "\n",
    "output=np.dot(weights,inputs)+bias  #element wise multiplication meaning weights[0]*input + bias and simliar\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "'''BATCH'''\n",
    "inputs=[[1,2,3,2.5],\n",
    "        [2.0,5.0,-1.0,2.0],\n",
    "        [-1.5,2.7,3.3,-0.8]]\n",
    "weights=[[0.2,0.8,-0.5,1.0],\n",
    "         [0.5,-0.91,0.26,-0.5],\n",
    "         [-0.26,-0.27,0.17,0.87]] \n",
    "biases=[2,3,0.5]\n",
    "weights2=[[0.1,-0.14,0.5],\n",
    "         [-0.5,0.12,-0.33],\n",
    "         [-0.44,0.73,-0.13]] \n",
    "biases2=[-1,2,-0.5]\n",
    "#layer 1 has 4 inputs 3 outputs and layer 2 has 3 inputs from layer 1 outputs and 3 outputs\n",
    "#the number of nodes(uniques sets of weights and biases) define the number of outputs\n",
    "#clearly \n",
    "layer1_outputs=np.dot(inputs,np.array(weights).T)+biases\n",
    "layer2_outputs=np.dot(layer1_outputs,np.array(weights2).T)+biases2\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10758131  1.03983522  0.24462411  0.31821498  0.18851053]\n",
      " [-0.08349796  0.70846411  0.00293357  0.44701525  0.36360538]\n",
      " [-0.50763245  0.55688422  0.07987797 -0.34889573  0.04553042]]\n",
      "[[ 0.148296   -0.08397602]\n",
      " [ 0.14100315 -0.01340469]\n",
      " [ 0.20124979 -0.07290616]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"OBJECTS\"\"\"\n",
    "\n",
    "#input data to out neural network\n",
    "#we have three samples\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "#the shape here is the nuumber of neurons x no. of inputs\n",
    "X= [[1,2,3,2.5],\n",
    "    [2.0,5.0,-1.0,2.0],\n",
    "    [-1.5,2.7,3.3,-0.8]]\n",
    "\n",
    "#now we are gonna deal with the layers in the neural network\n",
    "class Layer_Dense:\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights=0.1*np.random.randn(n_inputs,n_neurons) #this is reversed to eliminate transpose later on\n",
    "        self.biases=np.zeros((1,n_neurons))\n",
    "    def forward(self,inputs):\n",
    "        self.output=np.dot(inputs,self.weights)+self.biases\n",
    "\n",
    "layer1=Layer_Dense(4,5)\n",
    "layer2=Layer_Dense(5,2)\n",
    "\n",
    "layer1.forward(X)\n",
    "print(layer1.output)\n",
    "layer2.forward(layer1.output)\n",
    "print(layer2.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
